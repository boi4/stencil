#!/bin/bash

#SBATCH --nodes 1
#SBATCH --ntasks-per-node 1
#SBATCH --partition veryshort
#SBATCH --reservation COMS30005
#SBATCH --account COMS30005
#SBATCH --job-name stencil
#SBATCH --time 01:00:00
#SBATCH --output stencil.out
#SBATCH --exclusive

# Print some information about the job
echo "Running on host $(hostname)"
echo "Time is $(date)"
echo "Directory is $(pwd)"
echo "Slurm job ID is $SLURM_JOB_ID"
echo
echo "This job runs on the following machines:"
echo "$SLURM_JOB_NODELIST" | uniq
echo

# Enable using `srun` with Intel MPI
#export I_MPI_PMI_LIBRARY=/usr/lib64/libpmi.so

# Run the executable
#srun ./stencil 1024 1024 100

echo starting job

#advixe-cl -collect roofline -project-dir ./ -- ./out/iccadv 8000 8000 100
#advixe-cl -collect=survery -project-dir=./ -- ./out/iccadv 8000 8000 100
#advixe-cl -collect=tripcounts --flop -project-dir=./ -- ./out/iccadv 8000 8000 100

#perf stat   ./out/iccofast 1024 1024 100
#perf record ./out/iccofast 1024 1024 100
#perf report --stdio
#perf stat   ./out/iccofast 4096 4096 100
#perf record ./out/iccofast 4096 4096 100
#perf report --stdio
#perf stat   ./out/iccofast 8000 8000 100
#perf record ./out/iccofast 8000 8000 100
#perf report --stdio

python3 ./bench.py full
